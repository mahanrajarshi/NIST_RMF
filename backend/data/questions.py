"""
NIST AI RMF Assessment Questions
4 Functions, 19 Categories, ~72 subcategory questions
Each question scored on a 1-5 maturity scale
"""

MATURITY_LEVELS = {
    1: {"label": "Initial", "description": "Ad hoc, undocumented processes"},
    2: {"label": "Developing", "description": "Processes being defined but inconsistently applied"},
    3: {"label": "Defined", "description": "Standardized, documented processes in place"},
    4: {"label": "Managed", "description": "Processes measured and controlled"},
    5: {"label": "Optimizing", "description": "Continuous improvement and adaptation"},
}

FUNCTIONS = [
    {
        "id": "govern",
        "name": "GOVERN",
        "code": "GV",
        "description": "Cultivate and implement a culture of AI risk management within the organization.",
        "color": "#002FA7",
    },
    {
        "id": "map",
        "name": "MAP",
        "code": "MP",
        "description": "Establish context, identify AI risks and impacts across the system lifecycle.",
        "color": "#0F172A",
    },
    {
        "id": "measure",
        "name": "MEASURE",
        "code": "MS",
        "description": "Analyze, assess, and track identified AI risks using quantitative and qualitative methods.",
        "color": "#16A34A",
    },
    {
        "id": "manage",
        "name": "MANAGE",
        "code": "MG",
        "description": "Prioritize and act upon AI risks based on projected impact.",
        "color": "#DC2626",
    },
]

QUESTIONS = [
    # ========== GOVERN (GV) ==========
    # GV.1 - Policies
    {
        "id": "gv-1-1",
        "function": "govern",
        "category": "GV.1",
        "category_name": "AI Risk Management Policies",
        "question": "Does your organization have documented policies specifically addressing AI risk management?",
        "guidance": "Look for formal policy documents that outline AI governance, risk tolerance, and management procedures.",
        "weight": 3,
    },
    {
        "id": "gv-1-2",
        "function": "govern",
        "category": "GV.1",
        "category_name": "AI Risk Management Policies",
        "question": "Are AI risk management policies aligned with your organization's overall enterprise risk management strategy?",
        "guidance": "Assess whether AI-specific policies integrate with broader organizational risk frameworks (e.g., ERM, COSO).",
        "weight": 2,
    },
    {
        "id": "gv-1-3",
        "function": "govern",
        "category": "GV.1",
        "category_name": "AI Risk Management Policies",
        "question": "Are policies reviewed and updated regularly to reflect evolving AI risks and regulatory requirements?",
        "guidance": "Check for a defined review cycle (e.g., annual) and evidence of recent updates.",
        "weight": 2,
    },
    {
        "id": "gv-1-4",
        "function": "govern",
        "category": "GV.1",
        "category_name": "AI Risk Management Policies",
        "question": "Do policies address legal and regulatory compliance requirements for AI systems (e.g., EU AI Act, sector-specific regulations)?",
        "guidance": "Verify policies reference applicable regulations and define compliance obligations.",
        "weight": 3,
    },
    # GV.2 - Accountability
    {
        "id": "gv-2-1",
        "function": "govern",
        "category": "GV.2",
        "category_name": "Accountability Structures",
        "question": "Are clear roles and responsibilities defined for AI risk management across the organization?",
        "guidance": "Look for RACI matrices or organizational charts showing AI governance responsibilities.",
        "weight": 3,
    },
    {
        "id": "gv-2-2",
        "function": "govern",
        "category": "GV.2",
        "category_name": "Accountability Structures",
        "question": "Is there a designated senior leader or committee responsible for AI risk oversight?",
        "guidance": "Identify whether a CAIO, AI Ethics Board, or equivalent exists with defined authority.",
        "weight": 3,
    },
    {
        "id": "gv-2-3",
        "function": "govern",
        "category": "GV.2",
        "category_name": "Accountability Structures",
        "question": "Are accountability mechanisms in place to ensure AI risk decisions are documented and traceable?",
        "guidance": "Check for decision logs, audit trails, and sign-off processes for AI deployments.",
        "weight": 2,
    },
    # GV.3 - Workforce
    {
        "id": "gv-3-1",
        "function": "govern",
        "category": "GV.3",
        "category_name": "Workforce Diversity & AI Literacy",
        "question": "Does the organization provide AI risk management training to relevant staff?",
        "guidance": "Assess training programs covering AI ethics, bias awareness, and risk identification.",
        "weight": 2,
    },
    {
        "id": "gv-3-2",
        "function": "govern",
        "category": "GV.3",
        "category_name": "Workforce Diversity & AI Literacy",
        "question": "Is diversity of perspective ensured in AI development and risk management teams?",
        "guidance": "Look for diverse team composition including technical, legal, ethical, and domain expertise.",
        "weight": 2,
    },
    {
        "id": "gv-3-3",
        "function": "govern",
        "category": "GV.3",
        "category_name": "Workforce Diversity & AI Literacy",
        "question": "Are there mechanisms for staff to raise AI risk concerns without retaliation?",
        "guidance": "Check for whistleblower protections, anonymous reporting channels, or open-door policies.",
        "weight": 2,
    },
    # GV.4 - Organizational Commitments
    {
        "id": "gv-4-1",
        "function": "govern",
        "category": "GV.4",
        "category_name": "Organizational Commitments",
        "question": "Has the organization publicly committed to responsible AI principles?",
        "guidance": "Look for published AI ethics statements, responsible AI principles, or signed pledges.",
        "weight": 2,
    },
    {
        "id": "gv-4-2",
        "function": "govern",
        "category": "GV.4",
        "category_name": "Organizational Commitments",
        "question": "Are organizational values and principles integrated into AI system design and deployment decisions?",
        "guidance": "Assess whether AI development processes explicitly incorporate organizational values.",
        "weight": 2,
    },
    # GV.5 - Stakeholder Engagement
    {
        "id": "gv-5-1",
        "function": "govern",
        "category": "GV.5",
        "category_name": "Stakeholder Engagement",
        "question": "Does the organization engage external stakeholders (e.g., customers, communities) in AI risk discussions?",
        "guidance": "Check for stakeholder consultation processes, public comment periods, or advisory boards.",
        "weight": 2,
    },
    {
        "id": "gv-5-2",
        "function": "govern",
        "category": "GV.5",
        "category_name": "Stakeholder Engagement",
        "question": "Are feedback mechanisms in place for stakeholders affected by AI systems to report concerns?",
        "guidance": "Look for complaint procedures, feedback portals, or dedicated contact channels.",
        "weight": 2,
    },
    # GV.6 - Oversight
    {
        "id": "gv-6-1",
        "function": "govern",
        "category": "GV.6",
        "category_name": "Oversight & Monitoring",
        "question": "Are regular audits or reviews conducted on AI systems for risk and compliance?",
        "guidance": "Check for scheduled audit programs, internal review processes, or third-party assessments.",
        "weight": 3,
    },
    {
        "id": "gv-6-2",
        "function": "govern",
        "category": "GV.6",
        "category_name": "Oversight & Monitoring",
        "question": "Is there a process for continuous monitoring of AI system risks post-deployment?",
        "guidance": "Assess whether monitoring dashboards, alerting systems, or periodic reviews are in place.",
        "weight": 3,
    },
    {
        "id": "gv-6-3",
        "function": "govern",
        "category": "GV.6",
        "category_name": "Oversight & Monitoring",
        "question": "Does the organization maintain an inventory or registry of all AI systems in use?",
        "guidance": "Look for an AI system catalog with details on purpose, risk level, and status.",
        "weight": 2,
    },

    # ========== MAP (MP) ==========
    # MP.1 - Context
    {
        "id": "mp-1-1",
        "function": "map",
        "category": "MP.1",
        "category_name": "Context & Use Case Definition",
        "question": "Are the intended purposes and use cases for each AI system clearly documented?",
        "guidance": "Check for use case documentation, business requirements, and purpose statements.",
        "weight": 3,
    },
    {
        "id": "mp-1-2",
        "function": "map",
        "category": "MP.1",
        "category_name": "Context & Use Case Definition",
        "question": "Is the operational context (environment, users, constraints) for each AI system identified?",
        "guidance": "Assess documentation of deployment environments, user profiles, and technical constraints.",
        "weight": 2,
    },
    {
        "id": "mp-1-3",
        "function": "map",
        "category": "MP.1",
        "category_name": "Context & Use Case Definition",
        "question": "Are known limitations and boundaries of AI system capabilities documented?",
        "guidance": "Look for model cards, technical documentation, or capability boundary definitions.",
        "weight": 3,
    },
    {
        "id": "mp-1-4",
        "function": "map",
        "category": "MP.1",
        "category_name": "Context & Use Case Definition",
        "question": "Has the organization defined criteria for acceptable and unacceptable AI use cases?",
        "guidance": "Check for prohibited use policies, red-line criteria, or use case classification frameworks.",
        "weight": 2,
    },
    # MP.2 - Categorization
    {
        "id": "mp-2-1",
        "function": "map",
        "category": "MP.2",
        "category_name": "AI System Categorization",
        "question": "Are AI systems classified by risk level (e.g., high, medium, low) based on potential impact?",
        "guidance": "Check for risk tiering frameworks aligned with potential harm to individuals or society.",
        "weight": 3,
    },
    {
        "id": "mp-2-2",
        "function": "map",
        "category": "MP.2",
        "category_name": "AI System Categorization",
        "question": "Is the classification methodology consistent and applied uniformly across AI systems?",
        "guidance": "Verify standardized assessment criteria and consistent application across projects.",
        "weight": 2,
    },
    {
        "id": "mp-2-3",
        "function": "map",
        "category": "MP.2",
        "category_name": "AI System Categorization",
        "question": "Does categorization consider both technical risks (model failure, data quality) and societal risks (bias, fairness)?",
        "guidance": "Assess whether risk classification covers the full spectrum of AI-related risks.",
        "weight": 3,
    },
    # MP.3 - Benefits & Costs
    {
        "id": "mp-3-1",
        "function": "map",
        "category": "MP.3",
        "category_name": "Benefits & Costs Analysis",
        "question": "Does the organization conduct formal cost-benefit analyses for AI system deployments?",
        "guidance": "Look for documented analyses comparing expected benefits against potential risks and costs.",
        "weight": 2,
    },
    {
        "id": "mp-3-2",
        "function": "map",
        "category": "MP.3",
        "category_name": "Benefits & Costs Analysis",
        "question": "Are societal and environmental impacts considered alongside financial metrics in AI assessments?",
        "guidance": "Check whether impact assessments include social equity, environmental, and ethical dimensions.",
        "weight": 2,
    },
    # MP.4 - Risks & Impacts
    {
        "id": "mp-4-1",
        "function": "map",
        "category": "MP.4",
        "category_name": "Risk & Impact Identification",
        "question": "Are potential negative impacts of AI systems on individuals, groups, and society identified and documented?",
        "guidance": "Assess impact assessment processes including harm modeling and vulnerability analysis.",
        "weight": 3,
    },
    {
        "id": "mp-4-2",
        "function": "map",
        "category": "MP.4",
        "category_name": "Risk & Impact Identification",
        "question": "Are risks related to data quality, bias, and representativeness systematically evaluated?",
        "guidance": "Check for data audits, bias assessments, and dataset documentation processes.",
        "weight": 3,
    },
    {
        "id": "mp-4-3",
        "function": "map",
        "category": "MP.4",
        "category_name": "Risk & Impact Identification",
        "question": "Are adversarial threats and cybersecurity risks specific to AI systems assessed?",
        "guidance": "Look for threat modeling covering adversarial attacks, data poisoning, and model manipulation.",
        "weight": 3,
    },
    {
        "id": "mp-4-4",
        "function": "map",
        "category": "MP.4",
        "category_name": "Risk & Impact Identification",
        "question": "Is there a process for identifying emergent risks that may arise during AI system operation?",
        "guidance": "Assess whether monitoring for unexpected behaviors or distributional shifts is in place.",
        "weight": 2,
    },
    # MP.5 - Stakeholder Impact
    {
        "id": "mp-5-1",
        "function": "map",
        "category": "MP.5",
        "category_name": "Stakeholder Impact Assessment",
        "question": "Are all stakeholders who may be affected by AI systems identified and considered?",
        "guidance": "Check for stakeholder mapping including end users, affected communities, and third parties.",
        "weight": 2,
    },
    {
        "id": "mp-5-2",
        "function": "map",
        "category": "MP.5",
        "category_name": "Stakeholder Impact Assessment",
        "question": "Are differential impacts on vulnerable or marginalized populations specifically assessed?",
        "guidance": "Look for equity impact assessments or disparate impact analyses.",
        "weight": 3,
    },
    {
        "id": "mp-5-3",
        "function": "map",
        "category": "MP.5",
        "category_name": "Stakeholder Impact Assessment",
        "question": "Is stakeholder feedback systematically collected and incorporated into AI risk assessments?",
        "guidance": "Assess feedback collection mechanisms and evidence of incorporation into decision-making.",
        "weight": 2,
    },

    # ========== MEASURE (MS) ==========
    # MS.1 - Metrics
    {
        "id": "ms-1-1",
        "function": "measure",
        "category": "MS.1",
        "category_name": "Metrics & Methodologies",
        "question": "Has the organization defined specific metrics for measuring AI system trustworthiness (validity, reliability, safety)?",
        "guidance": "Look for defined KPIs covering accuracy, robustness, fairness, and safety metrics.",
        "weight": 3,
    },
    {
        "id": "ms-1-2",
        "function": "measure",
        "category": "MS.1",
        "category_name": "Metrics & Methodologies",
        "question": "Are measurement methodologies appropriate for the AI system type and risk level?",
        "guidance": "Assess whether testing approaches match the system's complexity and deployment context.",
        "weight": 2,
    },
    {
        "id": "ms-1-3",
        "function": "measure",
        "category": "MS.1",
        "category_name": "Metrics & Methodologies",
        "question": "Are fairness and bias metrics defined and regularly measured across protected characteristics?",
        "guidance": "Check for defined fairness criteria (e.g., demographic parity, equalized odds) and regular measurement.",
        "weight": 3,
    },
    {
        "id": "ms-1-4",
        "function": "measure",
        "category": "MS.1",
        "category_name": "Metrics & Methodologies",
        "question": "Are baseline measurements established to track AI system performance over time?",
        "guidance": "Look for documented baselines and trend analysis capabilities.",
        "weight": 2,
    },
    # MS.2 - Evaluation
    {
        "id": "ms-2-1",
        "function": "measure",
        "category": "MS.2",
        "category_name": "AI System Evaluation",
        "question": "Does the organization conduct Testing, Evaluation, Verification, and Validation (TEVV) for AI systems?",
        "guidance": "Check for structured TEVV processes including test plans, validation protocols, and results documentation.",
        "weight": 3,
    },
    {
        "id": "ms-2-2",
        "function": "measure",
        "category": "MS.2",
        "category_name": "AI System Evaluation",
        "question": "Are AI systems tested for robustness against adversarial inputs and edge cases?",
        "guidance": "Look for red-teaming exercises, adversarial testing, and stress testing documentation.",
        "weight": 3,
    },
    {
        "id": "ms-2-3",
        "function": "measure",
        "category": "MS.2",
        "category_name": "AI System Evaluation",
        "question": "Are evaluation results documented and shared with relevant decision-makers?",
        "guidance": "Assess whether test results are formally reported and influence deployment decisions.",
        "weight": 2,
    },
    {
        "id": "ms-2-4",
        "function": "measure",
        "category": "MS.2",
        "category_name": "AI System Evaluation",
        "question": "Is independent evaluation or third-party auditing conducted for high-risk AI systems?",
        "guidance": "Check whether external or independent teams validate AI system assessments.",
        "weight": 3,
    },
    # MS.3 - Transparency
    {
        "id": "ms-3-1",
        "function": "measure",
        "category": "MS.3",
        "category_name": "Transparency & Explainability",
        "question": "Are AI system outputs explainable to stakeholders at appropriate levels of technical detail?",
        "guidance": "Assess explainability methods (e.g., SHAP, LIME) and user-facing explanations.",
        "weight": 3,
    },
    {
        "id": "ms-3-2",
        "function": "measure",
        "category": "MS.3",
        "category_name": "Transparency & Explainability",
        "question": "Is information about AI system capabilities, limitations, and data usage transparently communicated?",
        "guidance": "Check for user disclosures, model cards, or transparency reports.",
        "weight": 2,
    },
    {
        "id": "ms-3-3",
        "function": "measure",
        "category": "MS.3",
        "category_name": "Transparency & Explainability",
        "question": "Are decision-making processes involving AI systems auditable and traceable?",
        "guidance": "Look for logging, audit trails, and the ability to reconstruct AI-informed decisions.",
        "weight": 3,
    },
    # MS.4 - Documentation
    {
        "id": "ms-4-1",
        "function": "measure",
        "category": "MS.4",
        "category_name": "Documentation & Monitoring",
        "question": "Are AI system performance metrics continuously monitored post-deployment?",
        "guidance": "Check for monitoring dashboards, alerting thresholds, and regular performance reviews.",
        "weight": 3,
    },
    {
        "id": "ms-4-2",
        "function": "measure",
        "category": "MS.4",
        "category_name": "Documentation & Monitoring",
        "question": "Is there a process for detecting and responding to model degradation or drift?",
        "guidance": "Assess drift detection mechanisms and defined response procedures.",
        "weight": 3,
    },
    {
        "id": "ms-4-3",
        "function": "measure",
        "category": "MS.4",
        "category_name": "Documentation & Monitoring",
        "question": "Are measurement results documented to support ongoing risk management and regulatory compliance?",
        "guidance": "Look for standardized documentation practices and retention policies.",
        "weight": 2,
    },

    # ========== MANAGE (MG) ==========
    # MG.1 - Risk Prioritization
    {
        "id": "mg-1-1",
        "function": "manage",
        "category": "MG.1",
        "category_name": "Risk Prioritization",
        "question": "Does the organization have a systematic process for prioritizing identified AI risks?",
        "guidance": "Check for risk ranking methodologies considering likelihood, impact, and urgency.",
        "weight": 3,
    },
    {
        "id": "mg-1-2",
        "function": "manage",
        "category": "MG.1",
        "category_name": "Risk Prioritization",
        "question": "Are resources allocated proportionally to the severity of identified AI risks?",
        "guidance": "Assess whether budget, staffing, and attention match the risk priority levels.",
        "weight": 2,
    },
    {
        "id": "mg-1-3",
        "function": "manage",
        "category": "MG.1",
        "category_name": "Risk Prioritization",
        "question": "Is there a defined threshold for when AI risks require escalation to senior leadership?",
        "guidance": "Look for escalation criteria, trigger points, and escalation procedures.",
        "weight": 3,
    },
    {
        "id": "mg-1-4",
        "function": "manage",
        "category": "MG.1",
        "category_name": "Risk Prioritization",
        "question": "Are risk priorities regularly reviewed and adjusted based on new information or changing conditions?",
        "guidance": "Check for dynamic risk reassessment processes and update cycles.",
        "weight": 2,
    },
    # MG.2 - Risk Treatment
    {
        "id": "mg-2-1",
        "function": "manage",
        "category": "MG.2",
        "category_name": "Risk Treatment Strategies",
        "question": "Are formal risk treatment plans developed for identified AI risks (mitigate, transfer, accept, avoid)?",
        "guidance": "Assess whether treatment strategies are documented with timelines and responsible parties.",
        "weight": 3,
    },
    {
        "id": "mg-2-2",
        "function": "manage",
        "category": "MG.2",
        "category_name": "Risk Treatment Strategies",
        "question": "Is there an incident response plan specifically for AI system failures or adverse events?",
        "guidance": "Check for AI-specific incident response procedures, communication plans, and rollback procedures.",
        "weight": 3,
    },
    {
        "id": "mg-2-3",
        "function": "manage",
        "category": "MG.2",
        "category_name": "Risk Treatment Strategies",
        "question": "Are risk mitigation effectiveness regularly assessed and adjustments made as needed?",
        "guidance": "Look for post-implementation reviews and effectiveness measurements.",
        "weight": 2,
    },
    {
        "id": "mg-2-4",
        "function": "manage",
        "category": "MG.2",
        "category_name": "Risk Treatment Strategies",
        "question": "Does the organization have procedures for decommissioning AI systems that pose unacceptable risks?",
        "guidance": "Check for sunset policies, decommission procedures, and criteria for system retirement.",
        "weight": 2,
    },
    # MG.3 - Third-Party
    {
        "id": "mg-3-1",
        "function": "manage",
        "category": "MG.3",
        "category_name": "Third-Party Risk Management",
        "question": "Are third-party AI components (models, APIs, data) assessed for risk before integration?",
        "guidance": "Check for vendor risk assessment processes and due diligence procedures.",
        "weight": 3,
    },
    {
        "id": "mg-3-2",
        "function": "manage",
        "category": "MG.3",
        "category_name": "Third-Party Risk Management",
        "question": "Are contractual requirements in place to ensure third-party AI providers meet risk management standards?",
        "guidance": "Assess SLAs, contractual clauses, and compliance requirements for AI vendors.",
        "weight": 2,
    },
    {
        "id": "mg-3-3",
        "function": "manage",
        "category": "MG.3",
        "category_name": "Third-Party Risk Management",
        "question": "Is there ongoing monitoring of third-party AI component performance and risk profiles?",
        "guidance": "Look for vendor monitoring processes, periodic reassessments, and performance tracking.",
        "weight": 2,
    },
    # MG.4 - Deployment Decisions
    {
        "id": "mg-4-1",
        "function": "manage",
        "category": "MG.4",
        "category_name": "Deployment & Post-Deployment",
        "question": "Is there a formal approval process (gate review) before AI systems are deployed to production?",
        "guidance": "Check for deployment checklists, sign-off processes, and go/no-go criteria.",
        "weight": 3,
    },
    {
        "id": "mg-4-2",
        "function": "manage",
        "category": "MG.4",
        "category_name": "Deployment & Post-Deployment",
        "question": "Are post-deployment monitoring plans established before AI system launch?",
        "guidance": "Assess whether monitoring requirements are defined as part of the deployment process.",
        "weight": 3,
    },
    {
        "id": "mg-4-3",
        "function": "manage",
        "category": "MG.4",
        "category_name": "Deployment & Post-Deployment",
        "question": "Are mechanisms in place for human override or intervention in AI system decisions?",
        "guidance": "Check for human-in-the-loop processes, override capabilities, and fallback procedures.",
        "weight": 3,
    },
    {
        "id": "mg-4-4",
        "function": "manage",
        "category": "MG.4",
        "category_name": "Deployment & Post-Deployment",
        "question": "Is there a process for incorporating lessons learned from AI incidents into future risk management?",
        "guidance": "Look for post-incident reviews, knowledge management, and process improvement mechanisms.",
        "weight": 2,
    },
]
