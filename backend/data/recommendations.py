"""
Industry-specific recommendations for NIST AI RMF compliance
"""

INDUSTRY_RECOMMENDATIONS = {
    "healthcare": {
        "name": "Healthcare",
        "code": "HC",
        "regulations": ["HIPAA", "FDA AI/ML Guidelines", "21st Century Cures Act"],
        "description": "Healthcare organizations face unique AI risks including patient safety, diagnostic accuracy, and health data privacy.",
        "recommendations": [
            {
                "function": "govern",
                "title": "Establish Clinical AI Governance Committee",
                "description": "Form a multidisciplinary committee including clinicians, data scientists, ethicists, and patient advocates to oversee AI deployment in clinical settings.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "govern",
                "title": "HIPAA-Aligned AI Data Governance",
                "description": "Implement strict data governance policies ensuring all AI training data and model outputs comply with HIPAA Privacy and Security Rules.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "map",
                "title": "Clinical Validation Requirements",
                "description": "Define rigorous clinical validation protocols for AI-assisted diagnostics and treatment recommendations, including prospective studies.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "map",
                "title": "Patient Safety Impact Assessment",
                "description": "Conduct systematic patient safety risk assessments for every AI system that directly or indirectly affects patient care decisions.",
                "priority": "critical",
                "effort": "medium",
            },
            {
                "function": "measure",
                "title": "Health Equity Bias Monitoring",
                "description": "Implement continuous monitoring for demographic bias in AI systems across race, gender, age, and socioeconomic factors in health outcomes.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "measure",
                "title": "FDA Pre-Submission Strategy",
                "description": "Develop a pre-submission strategy for AI/ML-based Software as a Medical Device (SaMD) following FDA's predetermined change control plan framework.",
                "priority": "high",
                "effort": "high",
            },
            {
                "function": "manage",
                "title": "Clinical Override Protocols",
                "description": "Establish clear protocols for clinician override of AI recommendations, with documentation requirements and feedback loops.",
                "priority": "critical",
                "effort": "medium",
            },
            {
                "function": "manage",
                "title": "AI Incident Reporting System",
                "description": "Implement a structured incident reporting system for AI-related adverse events, integrated with existing patient safety reporting.",
                "priority": "high",
                "effort": "medium",
            },
        ],
    },
    "finance": {
        "name": "Finance",
        "code": "FN",
        "regulations": ["SOX", "PCI-DSS", "Basel III/IV", "Dodd-Frank", "GDPR"],
        "description": "Financial institutions must address AI risks in credit scoring, fraud detection, algorithmic trading, and customer data protection.",
        "recommendations": [
            {
                "function": "govern",
                "title": "Model Risk Management Framework",
                "description": "Implement SR 11-7 compliant model risk management for all AI/ML models used in financial decision-making.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "govern",
                "title": "Fair Lending AI Compliance",
                "description": "Establish specific governance for AI models used in credit decisions, ensuring compliance with ECOA and Fair Housing Act.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "map",
                "title": "Algorithmic Trading Risk Assessment",
                "description": "Conduct comprehensive risk assessments for AI-driven trading systems including market impact, flash crash scenarios, and systemic risk.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "map",
                "title": "Customer Impact Analysis",
                "description": "Map all AI touchpoints in customer-facing processes and assess impact on financial well-being and service equity.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "measure",
                "title": "Adverse Action Explainability",
                "description": "Implement explainability frameworks for AI-driven adverse actions (credit denials, insurance rejections) that meet regulatory requirements.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "measure",
                "title": "Anti-Money Laundering AI Validation",
                "description": "Establish validation protocols for AI-based AML/KYC systems, including false positive/negative analysis and regulatory reporting accuracy.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "manage",
                "title": "Stress Testing AI Models",
                "description": "Include AI model performance in financial stress testing scenarios, assessing behavior under extreme market conditions.",
                "priority": "high",
                "effort": "high",
            },
            {
                "function": "manage",
                "title": "Regulatory Examination Preparedness",
                "description": "Maintain comprehensive documentation and audit trails for all AI models to support regulatory examinations and audits.",
                "priority": "critical",
                "effort": "medium",
            },
        ],
    },
    "government": {
        "name": "Government",
        "code": "GV",
        "regulations": ["FedRAMP", "EO 14110", "OMB M-24-10", "Privacy Act"],
        "description": "Government agencies must balance AI innovation with public trust, transparency, civil liberties, and democratic accountability.",
        "recommendations": [
            {
                "function": "govern",
                "title": "AI Use Case Inventory (EO 14110)",
                "description": "Maintain a public inventory of AI use cases as required by Executive Order 14110, including risk classifications and impact assessments.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "govern",
                "title": "Chief AI Officer Designation",
                "description": "Designate a Chief AI Officer with authority and resources to oversee AI risk management across the agency.",
                "priority": "critical",
                "effort": "medium",
            },
            {
                "function": "map",
                "title": "Rights-Impacting AI Assessment",
                "description": "Conduct rights-impact assessments for AI systems that affect public benefits, law enforcement, or civil liberties per OMB M-24-10.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "map",
                "title": "FedRAMP AI Security Assessment",
                "description": "Ensure all cloud-hosted AI systems meet FedRAMP security requirements with specific attention to AI-unique attack surfaces.",
                "priority": "high",
                "effort": "high",
            },
            {
                "function": "measure",
                "title": "Public Transparency Reporting",
                "description": "Publish regular transparency reports on AI system performance, decisions, and impacts to maintain public trust.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "measure",
                "title": "Equity Assessment Framework",
                "description": "Implement systematic equity assessments for AI systems affecting diverse populations, with public reporting of results.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "manage",
                "title": "AI Procurement Standards",
                "description": "Develop AI-specific procurement standards requiring vendors to demonstrate NIST AI RMF alignment and provide transparency documentation.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "manage",
                "title": "Human Oversight Requirements",
                "description": "Mandate human oversight for all AI-assisted decisions affecting individual rights or access to government services.",
                "priority": "critical",
                "effort": "medium",
            },
        ],
    },
    "defense": {
        "name": "Defense",
        "code": "DF",
        "regulations": ["CMMC", "DoD AI Strategy", "DIB Guidelines", "ITAR"],
        "description": "Defense organizations face unique AI challenges including autonomous systems, intelligence analysis, cybersecurity, and supply chain security.",
        "recommendations": [
            {
                "function": "govern",
                "title": "Responsible AI Principles Adoption",
                "description": "Formally adopt DoD Responsible AI principles: responsible, equitable, traceable, reliable, and governable for all AI systems.",
                "priority": "critical",
                "effort": "medium",
            },
            {
                "function": "govern",
                "title": "CMMC AI Integration",
                "description": "Integrate AI risk management into CMMC cybersecurity maturity requirements, addressing AI-specific threats to the defense industrial base.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "map",
                "title": "Autonomous Systems Risk Assessment",
                "description": "Conduct comprehensive risk assessments for autonomous and semi-autonomous AI systems with specific focus on human control and escalation.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "map",
                "title": "Adversarial AI Threat Modeling",
                "description": "Perform adversarial threat modeling specific to defense AI systems, including data poisoning, model manipulation, and supply chain attacks.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "measure",
                "title": "Operational Testing & Evaluation",
                "description": "Implement rigorous operational test and evaluation (OT&E) protocols for AI systems before operational deployment.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "measure",
                "title": "AI Supply Chain Verification",
                "description": "Establish verification processes for AI components, training data, and model provenance across the supply chain.",
                "priority": "high",
                "effort": "high",
            },
            {
                "function": "manage",
                "title": "Kill Chain Integration",
                "description": "Ensure human decision authority is maintained at appropriate levels in AI-augmented kill chains and targeting processes.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "manage",
                "title": "Classification-Aware AI Monitoring",
                "description": "Implement monitoring systems that operate within classified environments while maintaining audit trails for AI system decisions.",
                "priority": "high",
                "effort": "high",
            },
        ],
    },
    "technology": {
        "name": "Technology / SaaS",
        "code": "TC",
        "regulations": ["SOC 2", "ISO 27001", "EU AI Act", "CCPA/CPRA"],
        "description": "Technology companies must address AI risks in product development, user data handling, platform safety, and global regulatory compliance.",
        "recommendations": [
            {
                "function": "govern",
                "title": "AI Ethics Review Board",
                "description": "Establish an AI Ethics Review Board that evaluates high-impact product decisions and maintains independence from business units.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "govern",
                "title": "EU AI Act Compliance Program",
                "description": "Implement a structured compliance program for the EU AI Act, including risk classification, documentation, and conformity assessments.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "map",
                "title": "Product AI Risk Assessment",
                "description": "Integrate AI risk assessment into the product development lifecycle with mandatory checkpoints before feature releases.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "map",
                "title": "User Data Impact Assessment",
                "description": "Conduct privacy impact assessments for AI features processing user data, with attention to consent, purpose limitation, and data minimization.",
                "priority": "critical",
                "effort": "medium",
            },
            {
                "function": "measure",
                "title": "A/B Testing for AI Fairness",
                "description": "Implement A/B testing frameworks that specifically measure AI feature impact across demographic groups and use cases.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "measure",
                "title": "Model Performance SLAs",
                "description": "Define and monitor Service Level Agreements for AI model performance, including accuracy, latency, and availability metrics.",
                "priority": "high",
                "effort": "low",
            },
            {
                "function": "manage",
                "title": "Rapid AI Rollback Capability",
                "description": "Build infrastructure for rapid rollback of AI features, including feature flags, canary deployments, and automated quality gates.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "manage",
                "title": "Responsible Disclosure Program",
                "description": "Create a responsible AI disclosure program allowing researchers and users to report AI safety concerns and biases.",
                "priority": "high",
                "effort": "low",
            },
        ],
    },
    "energy": {
        "name": "Energy",
        "code": "EN",
        "regulations": ["NERC CIP", "DOE Guidelines", "EPA Regulations", "IEC 62443"],
        "description": "Energy sector AI applications span grid management, predictive maintenance, safety systems, and environmental compliance.",
        "recommendations": [
            {
                "function": "govern",
                "title": "Critical Infrastructure AI Policy",
                "description": "Develop AI governance policies that address critical infrastructure protection requirements under NERC CIP and sector-specific directives.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "govern",
                "title": "Safety-Critical AI Standards",
                "description": "Adopt IEC 62443 and IEC 61508 standards for AI systems operating in safety-critical energy environments.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "map",
                "title": "Grid Reliability Impact Analysis",
                "description": "Assess AI system impacts on grid reliability, stability, and resilience including cascade failure scenarios.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "map",
                "title": "Environmental Compliance AI Mapping",
                "description": "Map AI systems used in environmental monitoring and compliance reporting to ensure accuracy and regulatory adherence.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "measure",
                "title": "Real-Time Safety Monitoring",
                "description": "Implement real-time monitoring of AI systems managing safety-critical processes with automatic failsafe activation.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "measure",
                "title": "Predictive Maintenance Validation",
                "description": "Validate AI-based predictive maintenance models against actual failure data with regular accuracy assessments.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "manage",
                "title": "AI Failsafe Mechanisms",
                "description": "Design and test failsafe mechanisms for AI systems controlling physical processes, ensuring safe state defaults.",
                "priority": "critical",
                "effort": "high",
            },
            {
                "function": "manage",
                "title": "Cyber-Physical AI Incident Response",
                "description": "Develop incident response plans addressing AI failures in cyber-physical systems, including communication with grid operators.",
                "priority": "critical",
                "effort": "medium",
            },
        ],
    },
    "education": {
        "name": "Education",
        "code": "ED",
        "regulations": ["FERPA", "COPPA", "Section 508", "State AI Laws"],
        "description": "Educational institutions using AI must protect student privacy, ensure equitable access, and maintain academic integrity.",
        "recommendations": [
            {
                "function": "govern",
                "title": "FERPA-Compliant AI Governance",
                "description": "Establish AI governance policies that ensure all student data used in AI systems complies with FERPA requirements.",
                "priority": "critical",
                "effort": "medium",
            },
            {
                "function": "govern",
                "title": "Academic AI Use Policy",
                "description": "Develop clear policies on acceptable AI use by students, faculty, and staff, including generative AI tools.",
                "priority": "high",
                "effort": "low",
            },
            {
                "function": "map",
                "title": "Student Impact Assessment",
                "description": "Assess AI systems used in admissions, grading, and student support for potential discriminatory impacts.",
                "priority": "critical",
                "effort": "medium",
            },
            {
                "function": "map",
                "title": "Minor Data Protection (COPPA)",
                "description": "Ensure AI systems handling data of students under 13 comply with COPPA requirements, including parental consent.",
                "priority": "critical",
                "effort": "medium",
            },
            {
                "function": "measure",
                "title": "Learning Outcome Equity Metrics",
                "description": "Measure AI-assisted learning outcomes across demographic groups to identify and address achievement gaps.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "measure",
                "title": "Accessibility Compliance Testing",
                "description": "Test AI-powered educational tools for Section 508 accessibility compliance, ensuring equal access for students with disabilities.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "manage",
                "title": "Vendor AI Assessment Program",
                "description": "Implement a structured assessment program for EdTech vendors using AI, evaluating data practices, bias, and privacy protections.",
                "priority": "high",
                "effort": "medium",
            },
            {
                "function": "manage",
                "title": "AI Literacy Integration",
                "description": "Integrate AI literacy into curriculum to help students understand AI capabilities, limitations, and responsible use.",
                "priority": "medium",
                "effort": "medium",
            },
        ],
    },
}
